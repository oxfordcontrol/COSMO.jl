<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Method · COSMO.jl</title><meta name="title" content="Method · COSMO.jl"/><meta property="og:title" content="Method · COSMO.jl"/><meta property="twitter:title" content="Method · COSMO.jl"/><meta name="description" content="Documentation for COSMO.jl."/><meta property="og:description" content="Documentation for COSMO.jl."/><meta property="twitter:description" content="Documentation for COSMO.jl."/><meta property="og:url" content="https://oxfordcontrol.github.io/COSMO.jl/stable/method/"/><meta property="twitter:url" content="https://oxfordcontrol.github.io/COSMO.jl/stable/method/"/><link rel="canonical" href="https://oxfordcontrol.github.io/COSMO.jl/stable/method/"/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-134239283-1"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-134239283-1', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/><script src="../assets/github_buttons.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="COSMO.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">COSMO.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../jump/">JuMP Interface</a></li><li><a class="tocitem" href="../lin_solver/">Linear System Solver</a></li><li><a class="tocitem" href="../acceleration/">Acceleration</a></li><li><a class="tocitem" href="../literate/build/custom_cone/">Custom Cone Constraint</a></li><li><a class="tocitem" href="../decomposition/">Chordal Decomposition</a></li><li><a class="tocitem" href="../literate/build/portfolio_model_updates/">Model Updates</a></li><li><a class="tocitem" href="../literate/build/arbitrary_precision/">Arbitrary Precision</a></li><li><a class="tocitem" href="../performance/">Performance Tips</a></li></ul></li><li class="is-active"><a class="tocitem" href>Method</a><ul class="internal"><li><a class="tocitem" href="#Dual-problem"><span>Dual problem</span></a></li><li><a class="tocitem" href="#Algorithm"><span>Algorithm</span></a></li><li><a class="tocitem" href="#Scaling"><span>Scaling</span></a></li><li><a class="tocitem" href="#Termination-criteria"><span>Termination criteria</span></a></li><li><a class="tocitem" href="#Infeasibility-detection"><span>Infeasibility detection</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/closest_correlation_matrix/">Closest Correlation Matrix</a></li><li><a class="tocitem" href="../examples/logistic_regression/">Logistic Regression</a></li><li><a class="tocitem" href="../examples/lovasz_petersen/">Lovász Theta Function</a></li><li><a class="tocitem" href="../examples/lp/">Linear Program</a></li><li><a class="tocitem" href="../examples/maxcut/">Maximum Cut Problem</a></li><li><a class="tocitem" href="../examples/portfolio_optimisation/">Portfolio Optimisation</a></li><li><a class="tocitem" href="../examples/qp/">Quadratic Program</a></li><li><a class="tocitem" href="../examples/sum_abs_k_eigenvalues/">Minimizing the sum of the k-largest λ</a></li><li><a class="tocitem" href="../examples/svm_primal/">Support Vector Machine</a></li><li><a class="tocitem" href="../examples/two_way_partitioning/">Relaxed Two-Way Partitioning Problem</a></li></ul></li><li><a class="tocitem" href="../citing/">Citing COSMO</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Method</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Method</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/oxfordcontrol/COSMO.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/oxfordcontrol/COSMO.jl/blob/master/docs/src/method.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Method"><a class="docs-heading-anchor" href="#Method">Method</a><a id="Method-1"></a><a class="docs-heading-anchor-permalink" href="#Method" title="Permalink"></a></h1><p>This section describes COSMO&#39;s underlying ADMM algorithm and how the user can use the settings to adjust this algorithm. For a more detailed explanation take a look at the associated publication in <a href="../citing/#Citing-COSMO">Citing COSMO</a>.</p><p>COSMO solves problems with quadratic objective function and a number of conic constraints in the following form:</p><p class="math-container">\[\begin{array}{ll} \text{minimize} &amp; \textstyle{\frac{1}{2}}x^\top Px + q^\top x\\ \text{subject to} &amp; Ax + s = b \\ &amp; s \in \mathcal{K}, \end{array}\]</p><p>with primal decision variable <span>$x \in \mathbb{R}^n$</span>, primal slack variable <span>$s \in \mathbb{R}^m$</span>. The objective function is defined by positive semidefinite matrix <span>$P=P^\top \succeq 0$</span> and vector <span>$q \in \mathbb{R}^n$</span>. The constraints are defined by matrix <span>$A \in \mathbb{R}^{m \times n}$</span>, vector <span>$b \in \mathbb{R}^m$</span> and a non-empty, closed convex set <span>$\mathcal{K}$</span>. The convex set itself can be a Cartesian product of convex sets in the form:</p><p class="math-container">\[  \mathcal{K} = \mathcal{K}_1^{m_1} \times \mathcal{K}_2^{m_2} \times \cdots \times \mathcal{K}_N^{m_N}.\]</p><p>Accordingly, by an appropriate choice of convex sets one can represent any LP, QP, SOCP or SDP.</p><h2 id="Dual-problem"><a class="docs-heading-anchor" href="#Dual-problem">Dual problem</a><a id="Dual-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Dual-problem" title="Permalink"></a></h2><p>The dual problem of the optimisation problem above is given by:</p><p class="math-container">\[\begin{array}{ll}
\text{maximize}     &amp; -\textstyle{\frac{1}{2}}x^\top Px - b^\top  y - \text{sup}_{s \in \mathcal{K}}(-y^\top s ) \\
\text{subject to}  &amp; Px + A^\top  y = -q\\
&amp;            y \in (\mathcal{K}^\infty)^* ,
\end{array}\]</p><p>with dual variable <span>$y \in \mathbb{R}^m$</span>.</p><h2 id="Algorithm"><a class="docs-heading-anchor" href="#Algorithm">Algorithm</a><a id="Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm" title="Permalink"></a></h2><p>The algorithm considers a slightly transformed problem. By introducing two dummy variables <span>$\tilde{x} = x$</span> and <span>$\tilde{s} = s$</span> we can rewrite the original problem:</p><p class="math-container">\[\begin{array}{ll}
\text{minimize}     &amp; \textstyle{\frac{1}{2}}\tilde{x}^\top P \tilde{x} + q^\top \tilde{x} + \mathcal{I}_{Ax+s=b}(\tilde{x},\tilde{s}) + \mathcal{I}_{\mathcal{K}}(s)\\
\text{subject to}  &amp; (\tilde{x},\tilde{s}) = (x,s),
\end{array}\]</p><p>where indicator functions <span>$\mathcal{I}$</span> were used to move the constraints into the objective function. The resulting problem is now in the right format to apply the alternating direction method of multipliers (ADMM). To apply ADMM we first find the augmented Lagrangian <span>$L$</span>:</p><p class="math-container">\[  L(x,s,\tilde{x},\tilde{s},\lambda,y) = \textstyle{\frac{1}{2}}\tilde{x}^\top P\tilde{x} + q^\top \tilde{x} + \mathcal{I}_{Ax+s=b}(\tilde{x},\tilde{s}) + \mathcal{I}_{\mathcal{K}}(s) + \frac{\sigma}{2} \|\tilde{x} - x + \textstyle{\frac{1}{\sigma}} λ \|_2^2 + \frac{\rho}{2} \| \tilde{s} - s + \textstyle{\frac{1}{\rho}} y \|_2^2.\]</p><p>Minimizing the Lagrangian in an alternating fashion with respect to the two variable pairs <span>$(\tilde{x},\tilde{s})$</span> and <span>$(x,s)$</span> yields the following algorithm steps:</p><p class="math-container">\[\begin{aligned}
    ( \tilde{x}^{k+1},\tilde{s}^{k+1})  &amp;\rarr \underset{\tilde{x},\tilde{s}}{\text{argmin}}  L\left( \tilde{x},\tilde{s},x^k,s^k,y^k \right)\\
    x^{k+1} &amp;\larr \tilde{x}^{k+1}\\
    s^{k+1} &amp;\larr \underset{s}{\text{argmin }}\frac{\rho}{2} \|  \tilde{s}^{k+1}  - s+\textstyle{\frac{1}{\rho}}y^k \|_2^2 + I_{\mathcal{K}}(s), \\
    y^{k+1} &amp;\larr y^k + \rho \left( \tilde{s}^{k+1} -s^{k+1} \right).
\end{aligned}\]</p><p>By the construction of the ADMM method those iterates are converging to the global solution. These steps are executed in a loop until convergence. Two important parameters are the ADMM steps sizes <span>$\rho$</span> (<code>Settings.rho</code>) and <span>$\sigma$</span> (<code>Settings.sigma</code>) which can be adjusted via the solver settings.</p><p>The two most important steps of the algorithm happen in the first and third line. The evaluation of the first line turns out to be an equality constrained quadratic program. We get a solution for <span>$( \tilde{x}^{k+1},\tilde{s}^{k+1})$</span> at every iteration by solving the following linear system:</p><p class="math-container">\[\begin{aligned}
\begin{bmatrix}
P + \sigma I &amp; A^\top \\A &amp;- \frac{1}{\rho}I
    \end{bmatrix}\begin{bmatrix}\tilde{x}^{k+1} \\ \nu^{k+1}\end{bmatrix}&amp;= \begin{bmatrix}-q+\sigma x^k \\b-s^k+\frac{1}{\rho}y^k\end{bmatrix}\\
\tilde{s}^{k+1} &amp;= s^k - \frac{1}{\rho}\left(\nu^{k+1} + y^{k}\right).
\end{aligned}\]</p><p>Fortunately, the left hand matrix doesn&#39;t change, which is why COSMO only has to factor the matrix once at the start of the algorithm.</p><p>The second important step in the algorithm is the update equation for <span>$s^{k+1}$</span> which can be interpreted as a projection onto the constraint set <span>$\mathcal{K}$</span>:</p><p class="math-container">\[s^{k+1} = \Pi_{\mathcal{K}}\left( \tilde{s}^{k+1} + \frac{1}{\rho}y^k\right).\]</p><p>The computational cost of this projection is highly dependent on the constraints of the problem. While projections onto the zero set or the nonnegative orthant are inexpensive, projections onto the positive semidefinite cone of order <span>$N$</span> involve an eigen-decomposition. Since methods for eigen-decompositions have a complexity of <span>$\mathcal{O}(N^3)$</span> the projection can become the computationally most expensive operation of the algorithm.</p><h2 id="Scaling"><a class="docs-heading-anchor" href="#Scaling">Scaling</a><a id="Scaling-1"></a><a class="docs-heading-anchor-permalink" href="#Scaling" title="Permalink"></a></h2><p>The convergence of ADMM-based algorithms depends on the relative scaling of the problem data. Especially to improve the convergence of badly scaled problems, COSMO tries to rescale the data in a preprocessing step.</p><p>We rescale the equality constraints with diagonal positive semidefinite matrices <span>$D$</span> and <span>$E$</span>. The scaled problem is given by:</p><p class="math-container">\[\begin{array}{ll}
\text{minimize}     &amp; \textstyle{\frac{1}{2}} \hat{x}^\top \hat{P} \hat{x} + \hat{q}^\top \hat{x}\\
\text{subject to}  &amp; \hat{A} \hat{x} + \hat{s}  = \hat{b},  \\
            &amp;  \hat{s} \in E\mathcal{K},
\end{array}\]</p><p>with scaled problem data</p><p class="math-container">\[  \hat{P}=DPD, \quad \hat{q}=Dq,  \quad\hat{A}=EAD, \quad \hat{b}=Eb,\]</p><p>and the scaled convex cone <span>$E\mathcal{K} = \{Ev \in \mathbb{R}^m \mid v \in \mathcal{K} \}$</span>. After solving the scaled problem the original solution is obtained by reversing the scaling:</p><p class="math-container">\[   x = D\hat{x}, \quad s = E^{-1}\hat{s}, \quad y = E\hat{y}.\]</p><p>To obtain the scaling matrices <span>$D$</span> and <span>$E$</span> we use a modified Ruiz equilibration algorithm which involves a certain number of scaling iterations to equilibrate the column norms of the data matrices <span>$P$</span> and <span>$A$</span>. The number of these iterations can be adjusted by the user with <code>scaling</code>. To disable the scaling step set <code>scaling = 0</code>.</p><h2 id="Termination-criteria"><a class="docs-heading-anchor" href="#Termination-criteria">Termination criteria</a><a id="Termination-criteria-1"></a><a class="docs-heading-anchor-permalink" href="#Termination-criteria" title="Permalink"></a></h2><p>The COSMO algorithm can terminate for four reasons:</p><ul><li>The maximum number of allowed iterations has been reached. The user can specify this value in the solver settings with <code>max_iter</code>.</li><li>The solver runtime reaches the time limit specified by the user (<code>time_limit</code>).</li><li>COSMO detects an infeasible problem.</li><li>The iterates fulfil the termination criteria for convergence.</li></ul><p>COSMO uses the primal and dual residuals of the problem to determine if the algorithm has converged. The primal and dual residuals are given by:</p><p class="math-container">\[\begin{aligned}
r_p &amp;= Ax + s -b,\\
r_d &amp;= Px + q + A^T y.
\end{aligned}\]</p><p>The solver terminates when the <span>$\infty$</span>-norms of the residuals lie below a specified tolerance. COSMO uses the sum of an absolute and relative tolerance term:</p><p class="math-container">\[\begin{aligned}
  \|r_p^k \|_\infty &amp;\leq \epsilon_{\mathrm{abs}} + \epsilon_{\mathrm{rel}} \, \text{max} \left\{ \|Ax^k \|_\infty,\|s^k\|_\infty, \|b\|_\infty \right\},\\
   \|r_d^k\|_\infty &amp;\leq \epsilon_{\mathrm{abs}} + \epsilon_{\mathrm{rel}} \, \text{max} \left\{\|Px^k\|_\infty,\|q\|_\infty, \|A^\top y^k\|_\infty \right\}.
\end{aligned}\]</p><p>The absolute and relative tolerances <span>$\epsilon_{\mathrm{abs}}$</span>and <span>$\epsilon_{\mathrm{rel}}$</span> can be set by the user by specifying <code>eps_abs</code> and <code>eps_rel</code>. Furthermore, the user can adjust the number of iterations after which the convergence criteria are checked (<code>check_termination</code>).</p><h2 id="Infeasibility-detection"><a class="docs-heading-anchor" href="#Infeasibility-detection">Infeasibility detection</a><a id="Infeasibility-detection-1"></a><a class="docs-heading-anchor-permalink" href="#Infeasibility-detection" title="Permalink"></a></h2><p>COSMO uses conditions based on separating hyperplanes to detect infeasible problems. The conditions for COSMO&#39;s problem format have been developed in [1]. Define the convex set <span>$\mathcal{C} = \mathcal{-K} + \{b\}$</span> then we can use the following infeasibility conditions:</p><p class="math-container">\[\begin{aligned}
\mathcal{P} &amp;= \left\{x \in \mathbb{R}^n \mid  Px = 0, \, Ax \in \mathcal{C}^{\infty}, \, \langle  q,x \rangle &lt; 0  \right\} \\
\mathcal{D} &amp;= \left\{y \in \mathbb{R}^m \mid  A^\top  y  = 0,  \, \sigma_\mathcal{C}(y) &lt; 0 \right\}.
\end{aligned}\]</p><p>The existence of some <span>$y \in \mathcal{D}$</span> is a certificate that the problem is primal infeasible, while the existence of some <span>$x \in \mathcal{P}$</span> is a certificate for dual infeasibility. COSMO regularly checks above conditions to detect infeasible problems. If the detection is successful, the solver terminates and returns the status codes <code>:Primal_infeasible</code> or <code>:Dual_infeasible</code>. COSMO checks the conditions every <code>check_infeasibility</code> iterations, which can be adjusted by the user.</p><h3 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h3><p>[1] Banjac, G. et al. <em>Infeasibility detection in the alternating direction method of multipliers for convex optimization</em>. <a href="http://people.ee.ethz.ch/~gbanjac/pdfs/admm_infeas.pdf">Preprint</a>, 2017.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../performance/">« Performance Tips</a><a class="docs-footer-nextpage" href="../examples/closest_correlation_matrix/">Closest Correlation Matrix »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 6 May 2024 16:11">Monday 6 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
