<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Logistic Regression · COSMO.jl</title><meta name="title" content="Logistic Regression · COSMO.jl"/><meta property="og:title" content="Logistic Regression · COSMO.jl"/><meta property="twitter:title" content="Logistic Regression · COSMO.jl"/><meta name="description" content="Documentation for COSMO.jl."/><meta property="og:description" content="Documentation for COSMO.jl."/><meta property="twitter:description" content="Documentation for COSMO.jl."/><meta property="og:url" content="https://oxfordcontrol.github.io/COSMO.jl/stable/examples/logistic_regression/"/><meta property="twitter:url" content="https://oxfordcontrol.github.io/COSMO.jl/stable/examples/logistic_regression/"/><link rel="canonical" href="https://oxfordcontrol.github.io/COSMO.jl/stable/examples/logistic_regression/"/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-134239283-1"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-134239283-1', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><script src="../../assets/github_buttons.js"></script><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="COSMO.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">COSMO.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../../jump/">JuMP Interface</a></li><li><a class="tocitem" href="../../lin_solver/">Linear System Solver</a></li><li><a class="tocitem" href="../../acceleration/">Acceleration</a></li><li><a class="tocitem" href="../../literate/build/custom_cone/">Custom Cone Constraint</a></li><li><a class="tocitem" href="../../decomposition/">Chordal Decomposition</a></li><li><a class="tocitem" href="../../literate/build/portfolio_model_updates/">Model Updates</a></li><li><a class="tocitem" href="../../literate/build/arbitrary_precision/">Arbitrary Precision</a></li><li><a class="tocitem" href="../../performance/">Performance Tips</a></li></ul></li><li><a class="tocitem" href="../../method/">Method</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../closest_correlation_matrix/">Closest Correlation Matrix</a></li><li class="is-active"><a class="tocitem" href>Logistic Regression</a><ul class="internal"><li><a class="tocitem" href="#Visualizing-the-data"><span>Visualizing the data</span></a></li><li><a class="tocitem" href="#Defining-the-logistic-model"><span>Defining the logistic model</span></a></li><li><a class="tocitem" href="#Feature-mapping"><span>Feature mapping</span></a></li><li><a class="tocitem" href="#Transformation-into-a-conic-optimisation-problem"><span>Transformation into a conic optimisation problem</span></a></li><li><a class="tocitem" href="#Solving-the-optimisation-problem-directly-with-COSMO"><span>Solving the optimisation problem directly with COSMO</span></a></li></ul></li><li><a class="tocitem" href="../lovasz_petersen/">Lovász Theta Function</a></li><li><a class="tocitem" href="../lp/">Linear Program</a></li><li><a class="tocitem" href="../maxcut/">Maximum Cut Problem</a></li><li><a class="tocitem" href="../portfolio_optimisation/">Portfolio Optimisation</a></li><li><a class="tocitem" href="../qp/">Quadratic Program</a></li><li><a class="tocitem" href="../sum_abs_k_eigenvalues/">Minimizing the sum of the k-largest λ</a></li><li><a class="tocitem" href="../svm_primal/">Support Vector Machine</a></li><li><a class="tocitem" href="../two_way_partitioning/">Relaxed Two-Way Partitioning Problem</a></li></ul></li><li><a class="tocitem" href="../../citing/">Citing COSMO</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Logistic Regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Logistic Regression</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/oxfordcontrol/COSMO.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/oxfordcontrol/COSMO.jl/blob/master/examples/logistic_regression.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><p>The source files for all examples can be found in <a href="https://github.com/oxfordcontrol/COSMO.jl/tree/master/examples/">/examples</a>.</p><h1 id="Logistic-Regression"><a class="docs-heading-anchor" href="#Logistic-Regression">Logistic Regression</a><a id="Logistic-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Logistic-Regression" title="Permalink"></a></h1><p>The presented example is adapted from the <a href="https://www.coursera.org/learn/machine-learning">Machine Learning - course by Andrew Ng</a>.</p><p>In this example we use logistic regression to estimate the parameters <span>$\theta_i$</span> of a logistic model in a classification problem. We will first  transform the logistic regression problem into an exponential cone optimisation problem. We will then solve the optimisation problem with COSMO  and determine the model parameters and the decision boundary.</p><h2 id="Visualizing-the-data"><a class="docs-heading-anchor" href="#Visualizing-the-data">Visualizing the data</a><a id="Visualizing-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-data" title="Permalink"></a></h2><p>Before we start, let&#39;s load and take a look at the example data from <code>examples/chip_data.txt</code>:</p><pre><code class="language-julia hljs">using LinearAlgebra, SparseArrays, COSMO, JuMP
using Plots

# load example data
f = open(joinpath(@__DIR__, &quot;chip_data.txt&quot;))
lines = readlines(f)
close(f)
n_data = length(lines)
n_half = div(n_data, 2)
x1 = zeros(n_data)
x2 = zeros(n_data)
y = zeros(Float64, n_data)
for (i, l) in enumerate(lines)
    s = split(l, &quot;,&quot;)
    x1[i] = parse(Float64, s[1])
    x2[i] = parse(Float64, s[2])
    y[i] = parse(Float64, s[3])
end


# visualize data
plot(x1[1:n_half-1], x2[1:n_half-1], color = :blue, st=:scatter, markershape = :cross, aspect_ratio=:equal, label = &quot;Accepted&quot;, xlabel = &quot;x1 - Microchip Test Score 1&quot;, ylabel = &quot;x2 - Microchip Test Score 2&quot;)
plot!(x1[n_half:end], x2[n_half:end], color = :red, st=:scatter, markershape = :circle, label = &quot;Rejected&quot;)</code></pre><img src="f5fc5625.svg" alt="Example block output"/><p>The plot shows two test scores of <span>$n$</span> microchip samples from a fabrication plant and whether the chip passed the quality check. Based on this data we would like to build a logistic model that takes into account the test scores and helps us predict the likelihood of a chip being accepted.</p><h2 id="Defining-the-logistic-model"><a class="docs-heading-anchor" href="#Defining-the-logistic-model">Defining the logistic model</a><a id="Defining-the-logistic-model-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-the-logistic-model" title="Permalink"></a></h2><p>The logistic regression hypothesis is given by</p><p class="math-container">\[h_\theta(x) = g(\theta^\top x)\]</p><p>where <span>$g$</span> is the sigmoid function:</p><p class="math-container">\[g(\theta^\top x) = \frac{1}{1+\exp(-\theta^\top x)}.\]</p><p>The vector <span>$x$</span> represents the independent variables and <span>$\theta$</span> represents the model parameters. For our samples we set the dependent variable <span>$y =1$</span> if the chip was accepted and <span>$y = 0$</span> otherwise.</p><p>The function <span>$h_\theta(x)$</span> can be interpreted as the probability of the outcome being true rather than false. We want to find the parameters <span>$\theta$</span> that maximize the log-likelihood over all (independently Bernoulli distributed) observations</p><p class="math-container">\[J(\theta) = \sum_{i, y_i = 1} \log h_\theta(x_i) + \sum_{i, y_i = 0} \log (1-h_\theta(x_i)).\]</p><p>Consequently, we want to solve the following optimization problem:</p><p class="math-container">\[\text{minimize} \quad -J(\theta) + \mu \|\theta \|_2,\]</p><p>where we added a regularization term with parameter <span>$\mu$</span> to prevent overfitting.</p><h2 id="Feature-mapping"><a class="docs-heading-anchor" href="#Feature-mapping">Feature mapping</a><a id="Feature-mapping-1"></a><a class="docs-heading-anchor-permalink" href="#Feature-mapping" title="Permalink"></a></h2><p>As our dataset only has two independent variables (the test scores) our model <span>$y = \theta_0 + \theta_1 x_1 + \theta_2 x_2$</span> will have the form of a straight line. Looking at the plot one can see that a line will not perform well in separating the samples. Therefore, we will create more features based on each data point by mapping the original features (<span>$x_1$</span>, <span>$x_2$</span>) into all polynomial terms of <span>$x_1$</span> and <span>$x_2$</span> up to the 6th power:</p><p class="math-container">\[\text{map\_feature}(x_1,x_2) = [1, x_1, x_2, x_1^2, x_1x_2, x_2^2, x_1^3, \dots, x_1x_2^5, x_2^6 ]\]</p><p>This will create 28 features for each sample.</p><pre><code class="language-julia hljs">function map_feature(x1, x2)
  deg = 6
  x_new = ones(length(x1))
  for i = 1:deg, j = 0:i
      x_new = hcat(x_new, x1.^(i-j) .* x2.^j)
  end
  return x_new
end

X = map_feature(x1, x2);
size(X)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(118, 28)</code></pre><h2 id="Transformation-into-a-conic-optimisation-problem"><a class="docs-heading-anchor" href="#Transformation-into-a-conic-optimisation-problem">Transformation into a conic optimisation problem</a><a id="Transformation-into-a-conic-optimisation-problem-1"></a><a class="docs-heading-anchor-permalink" href="#Transformation-into-a-conic-optimisation-problem" title="Permalink"></a></h2><p>We can rewrite above likelihood maximisation problem as a conic optimisation problem with exponential-cone-, second-order-cone-, equality-, and inequality constraints:</p><p class="math-container">\[\begin{array}{ll}
\text{minimize}  &amp;\sum_i^n \epsilon_i + \mu v\\
\text{subject to}  &amp; \|\theta \|_2 \leq v\\
&amp;  \log(1 + \exp(-\theta^\top x_i)) \leq \epsilon_i  \quad \text{if } y_i = 1, \\
&amp; \log(1 + \exp(\theta^\top x_i)) \leq \epsilon_i  \quad\text{   otherwise.}
\end{array}\]</p><p>Implementing the constraint <span>$\log(1 + \exp(z)) \leq \epsilon$</span> for each of the <span>$n$</span> samples requires two exponential cone constraints, one inequality constraint and two equality constraints. To see this, take the exponential on both sides and then divide by <span>$\exp(\epsilon)$</span> to get:</p><p class="math-container">\[\exp(-\epsilon) + \exp(z - \epsilon) \leq 1.\]</p><p>This constraint is equivalent to:</p><p class="math-container">\[\begin{array}{ll}
(z - \epsilon, s_1, t_1) &amp;\in K_{\text{exp}}, \\
(-\epsilon, s_2, t_2) &amp;\in K_{\text{exp}}, \\
t_1 + t_2 &amp;\leq 1,\\
s_1 = s_2 &amp;= 1,
\end{array}\]</p><p>where we defined the exponential cone as:</p><p class="math-container">\[K_{\text{exp}} = \{(r, s, t) \mid s &gt;0, s \exp(r/s) \leq t \} \cup \{ r \leq 0, s = 0, t \geq 0 \}.\]</p><p>Based on this transformation our optimisation problem will have <span>$5n + n_\theta + 1$</span> variables, 1 SOCP constraint, <span>$2n$</span> exponential cone constraints, <span>$n$</span> inequality constraints and <span>$2n$</span> equality constraints. Let&#39;s model the problem with JuMP and COSMO:</p><pre><code class="language-julia hljs">n_theta = size(X, 2)
n = n_data
μ  = 1.

m = JuMP.Model(COSMO.Optimizer)
@variable(m, v)
@variable(m, θ[1:n_theta])
@variable(m, e[1:n])
@variable(m, t1[1:n])
@variable(m, t2[1:n])
@variable(m, s1[1:n])
@variable(m, s2[1:n])

@objective(m, Min, μ * v + sum(e))
@constraint(m, [v; θ] in MOI.SecondOrderCone(n_theta + 1))

# create the constraints for each sample points
for i = 1:n
  yi = y[i]
  x = X[i, :]
  yi == 1. ? (a = -1) : (a = 1)
  @constraint(m, [a * dot(θ, x) - e[i]; s1[i]; t1[i] ] in MOI.ExponentialCone())
  @constraint(m, [-e[i]; s2[i]; t2[i]] in MOI.ExponentialCone())
  @constraint(m, t1[i] + t2[i] &lt;= 1)
  @constraint(m, s1[i] == 1)
  @constraint(m, s2[i] == 1)
end
JuMP.optimize!(m)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">------------------------------------------------------------------
          COSMO v0.8.9 - A Quadratic Objective Conic Solver
                         Michael Garstka
                University of Oxford, 2017 - 2022
------------------------------------------------------------------

Problem:  x ∈ R^{619},
          constraints: A ∈ R^{1091x619} (4513 nnz),
          matrix size to factor: 1710x1710,
          Floating-point precision: Float64
Sets:     ZeroSet of dim: 236
          Box of dim: 118
          SecondOrderCone of dim: 29
          ExponentialCone of dim: 3
          ExponentialCone of dim: 3
          ... and 234 more
Settings: ϵ_abs = 1.0e-05, ϵ_rel = 1.0e-05,
          ϵ_prim_inf = 1.0e-04, ϵ_dual_inf = 1.0e-04,
          ρ = 0.1, σ = 1e-06, α = 1.6,
          max_iter = 5000,
          scaling iter = 10 (on),
          check termination every 25 iter,
          check infeasibility every 40 iter,
          KKT system solver: QDLDL
Acc:      Anderson Type2{QRDecomp},
          Memory size = 15, RestartedMemory,
          Safeguarded: true, tol: 2.0
Setup Time: 23.45ms

Iter:	Objective:	Primal Res:	Dual Res:	Rho:
1	-1.2883e+03	2.5314e+01	1.7951e+00	1.0000e-01
25	 4.4210e+01	4.2289e-02	1.8522e-02	1.0000e-01
50	 5.1983e+01	3.4538e-04	1.4769e-04	1.0000e-01
75	 5.1927e+01	2.0440e-05	9.3916e-06	1.0000e-01

------------------------------------------------------------------
&gt;&gt;&gt; Results
Status: Solved
Iterations: 75
Optimal objective: 51.93
Runtime: 0.889s (889.49ms)</code></pre><pre><code class="language-julia hljs">theta = value.(θ)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">28-element Vector{Float64}:
  2.6744881022317313
  1.7749123100576332
  2.9342821763027476
 -4.053080320508815
 -3.3812383592363866
 -4.053108056464002
  0.7775996395049541
 -1.0919461009999678
 -0.463117470220522
 -0.48895266528538284
  ⋮
 -1.2247649128253904
 -0.09277415476334717
 -2.6855801154564873
  0.4665503647478539
 -0.7660973460714833
  0.44945390336775703
 -1.1908820987503004
 -0.9542284204579881
 -1.191894409018452</code></pre><p>Once we have solved the optimisation problem and obtained the parameter vector <span>$\theta$</span>, we can plot the decision boundary. This can be done by evaluating our model over a grid of points <span>$(u,v)$</span> and then plotting the contour line where the function <span>$g$</span> returns a probability of <span>$p=0.5$</span>.</p><pre><code class="language-julia hljs"># First we evaluate our model over a grid of points z = θ&#39; x
u = collect(range(-1., stop = 1.5, length = 50))
v = collect(range(-1., stop = 1.5, length = 50))
z = zeros(length(u), length(v));
for i = 1:length(u), j = 1:length(v)
    z[i, j] = dot(map_feature(u[i], v[j]), theta);
end</code></pre><p>To add the decision boundary we have to plot the line indicating <span>$50\%$</span> probability of acceptance, i.e. <span>$g(\theta^\top x) = g(z)  = 0.5$</span> which we get at <span>$z=0$</span>.</p><pre><code class="language-julia hljs">plot(x1[1:n_half-1], x2[1:n_half-1], color = :blue, st = :scatter, markershape = :cross, aspect_ratio=:equal, label = &quot;Accepted&quot;, xlabel = &quot;x1 - Microchip Test Score 1&quot;, ylabel = &quot;x2 - Microchip Test Score 2&quot;)
plot!(x1[n_half:end], x2[n_half:end], color = :red, st = :scatter, markershape = :circle, label = &quot;Rejected&quot;)
contour!(u, v, z&#39;, levels = [0.], c = :black, linewidth = 2)</code></pre><img src="10279931.svg" alt="Example block output"/><h2 id="Solving-the-optimisation-problem-directly-with-COSMO"><a class="docs-heading-anchor" href="#Solving-the-optimisation-problem-directly-with-COSMO">Solving the optimisation problem directly with COSMO</a><a id="Solving-the-optimisation-problem-directly-with-COSMO-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-the-optimisation-problem-directly-with-COSMO" title="Permalink"></a></h2><p>We can solve the problem directly in COSMO by using its modeling interface. The problem will have <span>$nn = 5 n + n_\theta + 1$</span> variables. Let us define the cost function  <span>$\frac{1}{2}x^\top P x + q^\top x$</span>:</p><pre><code class="language-julia hljs">nn = 5 * n + n_theta +  1
P = spzeros(nn, nn)
q = zeros(nn)
q[1] = μ
for i = 1:n
  q[1 + n_theta + (i - 1) * 5 + 1] = 1.
end</code></pre><p>Next we define a function that creates the <code>COSMO.Constraints</code> for a given sample:</p><pre><code class="language-julia hljs"># the order of the variables
# v, thetas, [e1 t11 t12 s11 s12] [e2 t21 t22 s21 s22] ...
# for each sample create two exponential cone constraints,
# 1 nonnegatives constraint, 2 zeroset constraints
function add_log_regression_constraints!(constraint_list, x, y, n, sample_num)
  num_thetas = length(x)
  # 1st exponential cone constraint (zi - ei, s1, t1) in Kexp
  c_start = 1 + num_thetas + (sample_num - 1) * 5 + 1
  A = spzeros(3, n)
  A[1, c_start] = -1.
  y == 1. ? (a = -1) : (a = 1)
  for k = 1:num_thetas
    A[1, 2 + k - 1] = a * x[k]
  end
  A[2, c_start + 3] = 1.
  A[3, c_start + 1] = 1.
  b = zeros(3)
  push!(constraint_list, COSMO.Constraint(A, b, COSMO.ExponentialCone))

  # 2nd exponential cone constraint (-e, s2, t2)
  A = spzeros(3, n)
  A[1, c_start] = -1.
  A[2, c_start + 4] = 1.
  A[3, c_start + 2] = 1.
  b = zeros(3)
  push!(constraint_list, COSMO.Constraint(A, b, COSMO.ExponentialCone))

  # Nonnegatives constraint t1 + t2 &lt;= 1
  A = spzeros(1, n)
  A[1, c_start + 1] = -1.
  A[1, c_start + 2] = -1.
  b = [1.]
  push!(constraint_list, COSMO.Constraint(A, b, COSMO.Nonnegatives))

  # ZeroSet constraint s1 == 1, s2 == 1
  A = spzeros(2, n)
  A[1, c_start + 3] = 1.
  A[2, c_start + 4] = 1.
  b = -1 * ones(2)
  push!(constraint_list, COSMO.Constraint(A, b, COSMO.ZeroSet))
end
nothing</code></pre><p>Now we can use this function to loop over the sample points and add the constraints to our constraint list:</p><pre><code class="language-julia hljs">constraint_list = Array{COSMO.Constraint{Float64}}(undef, 0)
for i = 1:n
  add_log_regression_constraints!(constraint_list, X[i, :], y[i], nn, i )
end</code></pre><p>It remains to add a second order cone constraint for the regularisation term: <span>$\|\theta \|_2 \leq v$</span></p><pre><code class="language-julia hljs">push!(constraint_list, COSMO.Constraint(Matrix(1.0I, n_theta + 1, n_theta + 1), zeros(n_theta + 1), COSMO.SecondOrderCone, nn, 1:n_theta+1));</code></pre><p>We can now create, assemble, and solve our <code>COSMO.Model</code>:</p><pre><code class="language-julia hljs">model = COSMO.Model()
assemble!(model, P, q, constraint_list, settings = COSMO.Settings(verbose=true))
res = COSMO.optimize!(model);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">------------------------------------------------------------------
          COSMO v0.8.9 - A Quadratic Objective Conic Solver
                         Michael Garstka
                University of Oxford, 2017 - 2022
------------------------------------------------------------------

Problem:  x ∈ R^{619},
          constraints: A ∈ R^{1091x619} (4513 nnz),
          matrix size to factor: 1710x1710,
          Floating-point precision: Float64
Sets:     ZeroSet of dim: 236
          Nonnegatives of dim: 118
          SecondOrderCone of dim: 29
          ExponentialCone of dim: 3
          ExponentialCone of dim: 3
          ... and 234 more
Settings: ϵ_abs = 1.0e-05, ϵ_rel = 1.0e-05,
          ϵ_prim_inf = 1.0e-04, ϵ_dual_inf = 1.0e-04,
          ρ = 0.1, σ = 1e-06, α = 1.6,
          max_iter = 5000,
          scaling iter = 10 (on),
          check termination every 25 iter,
          check infeasibility every 40 iter,
          KKT system solver: QDLDL
Acc:      Anderson Type2{QRDecomp},
          Memory size = 15, RestartedMemory,
          Safeguarded: true, tol: 2.0
Setup Time: 1.09ms

Iter:	Objective:	Primal Res:	Dual Res:	Rho:
1	-1.2883e+03	2.5314e+01	1.7951e+00	1.0000e-01
25	 4.5884e+01	3.4757e-02	1.0876e-02	1.0000e-01
50	 5.2041e+01	3.4769e-04	1.3217e-04	1.0000e-01
75	 5.1927e+01	1.6158e-05	1.1849e-05	1.0000e-01

------------------------------------------------------------------
&gt;&gt;&gt; Results
Status: Solved
Iterations: 75
Optimal objective: 51.93
Runtime: 0.189s (189.49ms)</code></pre><p>Let us double check that we get the same <span>$\theta$</span> as in the previous section:</p><pre><code class="language-julia hljs">using Test
theta_cosmo = res.x[2:2+n_theta-1]
@test norm(theta_cosmo - theta) &lt; 1e-4</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr32"><span class="sgr1">Test Passed</span></span></code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../closest_correlation_matrix/">« Closest Correlation Matrix</a><a class="docs-footer-nextpage" href="../lovasz_petersen/">Lovász Theta Function »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 6 May 2024 15:57">Monday 6 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
